# PenguinCode Configuration
# Target Hardware: NVIDIA RTX 4060 Ti (8GB VRAM)
# All defaults optimized for 8GB VRAM

ollama:
  api_url: "http://localhost:11434"
  timeout: 120

# Global model roles (fallback defaults - optimized for 8GB VRAM)
models:
  planning: "deepseek-coder:6.7b"
  orchestration: "llama3.2:3b"
  research: "llama3.2:3b"
  execution: "qwen2.5-coder:7b"

# Per-agent model overrides (optimized for RTX 4060 Ti 8GB)
agents:
  executor:
    model: "qwen2.5-coder:7b"
    description: "Code mutations, file writes, bash execution"
  explorer:
    model: "llama3.2:3b"
    description: "Codebase navigation, file reading, search"
  reviewer:
    model: "codellama:7b"
    description: "Code review, quality analysis"
  planner:
    model: "deepseek-coder:6.7b"
    description: "Implementation planning, task decomposition"
  tester:
    model: "qwen2.5-coder:7b"
    description: "Test generation and execution"
  refactor:
    model: "codellama:7b"
    description: "Refactoring suggestions and improvements"
  debugger:
    model: "deepseek-coder:6.7b"
    description: "Error analysis, debugging, fix suggestions"
  docs:
    model: "mistral:7b"
    description: "Documentation generation"
  researcher:
    model: "llama3.2:3b"
    description: "Web research, summarization"

defaults:
  temperature: 0.7
  max_tokens: 4096
  context_window: 8192

security:
  level: 2  # 1=always prompt, 2=prompt for destructive, 3=no prompts

history:
  enabled: true
  location: "per-project"
  max_sessions: 50

web_search:
  provider: "duckduckgo"
  max_results: 5
  safesearch: "moderate"

# GPU Regulators (rate limiting to prevent overload)
regulators:
  auto_detect: true
  gpu_type: "auto"
  gpu_model: ""
  vram_mb: 8192
  max_concurrent_requests: 2
  max_models_loaded: 1
  request_queue_size: 10
  min_request_interval_ms: 100
  cooldown_after_error_ms: 1000

# Optional: Hosted Ollama usage API (for quota tracking)
usage_api:
  enabled: false
  endpoint: "https://ollama.example.com/api/usage"
  jwt_token: "${OLLAMA_USAGE_JWT}"
  refresh_interval: 300
  show_warnings_at: 80
